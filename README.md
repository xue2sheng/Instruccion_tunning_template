# InstrucciÃ³n turning / Templates
Usar plantillas fijas de [instrucciones optimizadas](https://www.ibm.com/es-es/think/topics/instruction-tuning). Algunas fuentes para consular:

---
**1. IBM â€“ Instruction Tuning**
- **Enlace:** [IBM â€“ Instruction Tuning](https://www.ibm.com/es-es/think/topics/instruction-tuning)
- **DescripciÃ³n:** Explica el concepto de instruction tuning, cÃ³mo estructurar prompts y ejemplos para datasets de entrenamiento, incluyendo clasificaciÃ³n, extracciÃ³n y generaciÃ³n de texto.

---
**2. Hugging Face â€“ Datasets y Prompt Engineering**
- **Enlace:** [Hugging Face Datasets](https://huggingface.co/docs/datasets/)
- **DescripciÃ³n:** La documentaciÃ³n de Hugging Face incluye ejemplos de cÃ³mo estructurar datasets para fine-tuning, con plantillas para tareas como clasificaciÃ³n, QA, y generaciÃ³n de texto.

---
**3. Google â€“ Prompt Engineering Guide**
- **Enlace:** [Google â€“ Prompt Engineering Guide](https://ai.google.dev/docs/prompt_guide)
- **DescripciÃ³n:** GuÃ­a prÃ¡ctica sobre cÃ³mo diseÃ±ar prompts efectivos, con ejemplos de instrucciones claras y respuestas esperadas, aplicables a mÃºltiples idiomas.

---
**4. Papers With Code â€“ Instruction Tuning**
- **Enlace:** [Papers With Code â€“ Instruction Tuning](https://paperswithcode.com/method/instruction-tuning)
- **DescripciÃ³n:** Recopila papers y ejemplos de instruction tuning, incluyendo datasets pÃºblicos y estructuras de prompts para diferentes tareas de NLP.

---
**5. Stanford NLP â€“ Datasets y Ejemplos**
- **Enlace:** [Stanford NLP](https://nlp.stanford.edu/)
- **DescripciÃ³n:** Ofrece recursos y ejemplos de cÃ³mo estructurar datos para entrenamiento supervisado, con Ã©nfasis en consistencia y evaluaciÃ³n automÃ¡tica.

---
**6. GitHub â€“ Datasets para Fine-Tuning**
- **Ejemplo:** [Datasets de Hugging Face en GitHub](https://github.com/huggingface/datasets)
- **DescripciÃ³n:** Repositorios con datasets estructurados para fine-tuning, incluyendo ejemplos en espaÃ±ol y otros idiomas.

---
**7. ArXiv â€“ Papers sobre Instruction Tuning**
- **Ejemplo:** [FLAN: Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2109.01652)
- **DescripciÃ³n:** Paper que detalla cÃ³mo estructurar instrucciones y ejemplos para mejorar el rendimiento de modelos de lenguaje.

---

### Plantilla general
Esquema para construir ejemplos consistentes en el dataset:

- Tarea: Describe de forma breve y accionable lo que debe hacer el modelo.  
- Datos: Proporciona el contenido de entrada necesario para cumplir la tarea.  
- Respuesta esperada: Muestra exactamente el formato y el contenido objetivo que el modelo deberÃ­a producir.

### Ejemplo 1 (clasificaciÃ³n)
- Tarea: Clasifica el sentimiento del texto como â€œpositivoâ€, â€œnegativoâ€ o â€œneutroâ€.  
- Datos: â€œEl producto llegÃ³ antes de lo previsto y funciona perfectamente.â€  
- Respuesta esperada: positivo

### Ejemplo 2 (extracciÃ³n estructurada)
- Tarea: Extrae entidades de tipo persona, organizaciÃ³n y fecha en formato JSON con claves â€œpersonasâ€, â€œorganizacionesâ€, â€œfechasâ€.  
- Datos: â€œMarÃ­a GÃ³mez firmÃ³ un acuerdo con TechNova el 12 de septiembre de 2024.â€  
- Respuesta esperada: {"personas":["MarÃ­a GÃ³mez"],"organizaciones":["TechNova"],"fechas":["2024-09-12"]}

### Ejemplo 3 (transformaciÃ³n de texto)
- Tarea: Reescribe el texto en voz activa, manteniendo el significado y el idioma.  
- Datos: â€œEl informe fue revisado por el equipo de calidad antes de su publicaciÃ³n.â€  
- Respuesta esperada: â€œEl equipo de calidad revisÃ³ el informe antes de su publicaciÃ³n.â€

### Ejemplo 4 (QA con formato fijo)
- Tarea: Responde a la pregunta usando solo la evidencia, en mÃ¡ximo dos frases, y devuelve tambiÃ©n una puntuaciÃ³n de confianza entre 0 y 1.  
- Datos: â€œEvidencia: La capital de Chile es Santiago. Pregunta: Â¿CuÃ¡l es la capital de Chile?â€  
- Respuesta esperada: â€œLa capital de Chile es Santiago. Confianza: 0.98â€

### Ejemplo 5 (instrucciÃ³n + validaciÃ³n)
- Tarea: Resume el texto en â‰¤30 palabras y termina con una etiqueta [OK] si el resumen estÃ¡ dentro del lÃ­mite; de lo contrario, usa [EXCESO].  
- Datos: â€œEl comitÃ© anunciÃ³ nuevas directrices para la presentaciÃ³n de proyectos de investigaciÃ³n, con Ã©nfasis en transparencia de datos y reproducibilidad.â€  
- Respuesta esperada: â€œEl comitÃ© publicÃ³ directrices para propuestas de investigaciÃ³n, priorizando transparencia de datos y reproducibilidad. [OK]â€

### Nota de uso
- Mantener campos estables (â€œTareaâ€, â€œDatosâ€, â€œRespuesta esperadaâ€) facilita el entrenamiento supervisado y las evaluaciones automÃ¡ticas.  
- Para datasets conversacionales, se puede mapear â€œTareaâ€ a rol sistema/usuario, â€œDatosâ€ a contenido del usuario y â€œRespuesta esperadaâ€ al contenido del asistente, preservando el formato requerido por el modelo.

## Ejemplos extras

Â¡Excelente! AquÃ­ tienes mÃ¡s ejemplos de **prompts de instrucciÃ³n tuning** y **plantillas** en espaÃ±ol, organizados por tipo de tarea y con variaciones Ãºtiles para datasets de entrenamiento. Incluyo tambiÃ©n ejemplos para contextos conversacionales y tareas mÃ¡s complejas.

---

## **1. Plantillas para Tareas EspecÃ­ficas**

### **ClasificaciÃ³n Avanzada**
- **Tarea:** Clasifica el texto segÃºn la intenciÃ³n del usuario: â€œconsultaâ€, â€œquejaâ€, â€œsolicitud de informaciÃ³nâ€, â€œelogioâ€.
- **Datos:** â€œNo entiendo por quÃ© mi pedido aÃºn no ha llegado. Llevan dos semanas de retraso.â€
- **Respuesta esperada:** queja

### **ExtracciÃ³n con Relaciones**
- **Tarea:** Extrae las relaciones entre personas y organizaciones en formato JSON, usando las claves â€œpersonaâ€, â€œrolâ€, â€œorganizaciÃ³nâ€.
- **Datos:** â€œAna LÃ³pez fue nombrada directora de InnovaciÃ³n en GreenTech el mes pasado.â€
- **Respuesta esperada:**
  ```json
  {"relaciones": [{"persona": "Ana LÃ³pez", "rol": "directora de InnovaciÃ³n", "organizaciÃ³n": "GreenTech"}]}
  ```

### **GeneraciÃ³n Condicional**
- **Tarea:** Genera una respuesta de correo electrÃ³nico formal si el tono del mensaje original es â€œurgenteâ€; de lo contrario, usa un tono neutral.
- **Datos:** â€œNecesito que me envÃ­es el informe antes de las 3 pm hoy, es crÃ­tico para la reuniÃ³n.â€
- **Respuesta esperada:**
  ```
  Estimado/a [Nombre],
  He recibido su solicitud y le confirmo que el informe estarÃ¡ en su bandeja antes de las 3 pm.
  Quedo atento/a a cualquier otra necesidad urgente.
  Saludos cordiales,
  [Firma]
  ```

---

## **2. Plantillas para Datasets Conversacionales**

### **DiÃ¡logo con Roles**
- **Tarea:** Simula una conversaciÃ³n entre un usuario y un asistente virtual. El asistente debe responder con empatÃ­a y ofrecer soluciones prÃ¡cticas.
- **Datos:**
  - **Usuario:** â€œMi tarjeta de crÃ©dito no funciona en el extranjero, Â¿quÃ© hago?â€
  - **Asistente:** â€œLamento escuchar eso. Â¿PodrÃ­a confirmarme si activÃ³ la opciÃ³n de uso internacional en su cuenta? Si no, puedo guiarle para hacerlo ahora mismo.â€

### **Respuesta con ValidaciÃ³n**
- **Tarea:** Responde a la pregunta del usuario y valida si la respuesta cumple con las polÃ­ticas de la empresa (ejemplo: no prometer plazos no confirmados).
- **Datos:** â€œÂ¿CuÃ¡ndo llegarÃ¡ mi paquete?â€
- **Respuesta esperada:** â€œSegÃºn el seguimiento, su paquete estÃ¡ en trÃ¡nsito y la fecha estimada de entrega es el 10 de octubre. [Cumple polÃ­ticas]â€

---

## **3. Plantillas para Tareas Creativas**

### **GeneraciÃ³n de Contenido con Restricciones**
- **Tarea:** Escribe un post para redes sociales promocionando un producto, usando â‰¤140 caracteres y incluyendo un emoji.
- **Datos:** â€œNuevo lanzamiento: auriculares inalÃ¡mbricos con cancelaciÃ³n de ruido.â€
- **Respuesta esperada:** â€œğŸ§ Â¡Escucha solo lo que quieres! Nuevos auriculares inalÃ¡mbricos con cancelaciÃ³n de ruido. Â¡Disponibles ya! #SonidoPerfectoâ€

### **TransformaciÃ³n de Estilo**
- **Tarea:** Convierte el texto formal a un estilo coloquial, manteniendo la informaciÃ³n clave.
- **Datos:** â€œSe les informa que la reuniÃ³n programada para el dÃ­a de maÃ±ana ha sido pospuesta hasta nuevo aviso.â€
- **Respuesta esperada:** â€œOye, la reuniÃ³n de maÃ±ana se moviÃ³, te aviso cuando sepamos la nueva fecha.â€

---

## **4. Plantillas para EvaluaciÃ³n AutomÃ¡tica**

### **Respuesta con MÃ©tricas**
- **Tarea:** Responde la pregunta y asigna una puntuaciÃ³n de claridad (1-5) y relevancia (1-5) a tu respuesta.
- **Datos:** â€œÂ¿CÃ³mo puedo resetear la contraseÃ±a de mi cuenta?â€
- **Respuesta esperada:**
  ```
  Para resetear su contraseÃ±a, vaya a 'Iniciar sesiÃ³n', haga clic en 'Â¿OlvidÃ³ su contraseÃ±a?' e ingrese su correo electrÃ³nico. RecibirÃ¡ un enlace para crear una nueva.
  Claridad: 5
  Relevancia: 5
  ```

### **ComparaciÃ³n de Respuestas**
- **Tarea:** Genera dos respuestas posibles a la misma pregunta y selecciona la mejor segÃºn los criterios: claridad, empatÃ­a y precisiÃ³n.
- **Datos:** â€œMi vuelo fue cancelado, Â¿quÃ© opciones tengo?â€
- **Respuesta esperada:**
  - **OpciÃ³n A:** â€œLamentamos la cancelaciÃ³n. Puede solicitar un reembolso o reprogramar su vuelo sin costo.â€
  - **OpciÃ³n B:** â€œEntendemos su frustraciÃ³n. Le ofrecemos reembolso total o reprogramaciÃ³n prioritaria. Â¿Prefiere que le ayudemos con alguna de estas opciones?â€
  - **SelecciÃ³n:** OpciÃ³n B (mejor empatÃ­a y claridad)

---

## **5. Plantillas para Tareas MultilingÃ¼es**

### **TraducciÃ³n con AdaptaciÃ³n Cultural**
- **Tarea:** Traduce el texto al espaÃ±ol (EspaÃ±a) y adapta las referencias culturales si es necesario.
- **Datos:** â€œPlease bring a dish to pass for the potluck at the office.â€
- **Respuesta esperada:** â€œPor favor, trae un plato para compartir en la comida colectiva de la oficina.â€

---

## **Notas Clave**
- **Consistencia:** Usar siempre los mismos campos (â€œTareaâ€, â€œDatosâ€, â€œRespuesta esperadaâ€) facilita el entrenamiento y la evaluaciÃ³n.
- **Variedad:** Incluir ejemplos con errores comunes (ej: respuestas fuera de formato) ayuda a robustecer el modelo.
- **Contexto:** Para tareas conversacionales, aÃ±adir el historial de la conversaciÃ³n como parte de â€œDatosâ€ mejora la coherencia.



